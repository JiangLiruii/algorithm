网页爬虫说起位图, 在爬取网页的时候往往需要过滤掉已经爬过的页面, 不然会造成重复爬取, 假设有几十亿甚至上百亿的网页需要爬, 如何设计一个数据结构可以很快的判断待爬取的网页是否已经爬取过了? 该数据结构必须满足:

1 省内存, 因为量很大
2 查找和添加的复杂度不能太高

很自然的就会想到散列表, 假设一个URL 为64字节, 假设有10亿个 URL,那么60GB, 散列表还需要维持一个较小的装载因子, 并且用链表解决冲突的散列表还会储存链表指针, 有可能会超过100GB, 可以采取分治的思想, 将这100GB 分布到20台8GB 的电脑上.

有没有办法可以优化的呢?节省内存消耗.

布隆过滤器(Bloom Filter)可以满足要求

先说位图(bitmap), 因为布隆过滤器是基于位图的.

如果有1千万个整数, 范围在1到1亿之间, 如何快速查找某个整数在这1千万个整数之间?

申请一个大小为1亿, 数据类型为布尔类型的数组, 将这1千万个整数作为数组下标, 将对应的 value 设置为 true(默认为 false), 当查询某个整数 K 是否在这一千万个整数中的时候, 只需要将 array[K]取出来看 value 是否等于 true.

这样就可以将1千万个32位数(4字节)需要的40MB变成了一个大小为1亿的二进制位, 也就是12MB.
但是要注意一定是在较小的范围内, 如果是1到10亿, 那么大小就变成了120MB, 不降反增

布隆过滤器就是对位图的改进.

还是那个例子, 1千万个数, 现在的数据范围是1到10亿, 布隆过滤器的做法是仍让使用一个1亿个二进制大小的位图, 然后通过 hash 函数对数字进行处理, 让它落在这1到1亿范围内.

比如设计成 f(x) = x%n n是位图的大小, x 为数字的大小

但是肯定会有冲突, 所以就使用多个哈希函数一起定位一个数据去降低冲突.比如有 K 个哈希函数, 对同一个数求哈希值, 会得到 K 个不同的哈希值, 分别记做 X1,X2,X3...Xk,把位图中的所有对应的下标都设置为 true,查询的时候需要判断这些位都为 true, 才能判断这个数存在.仍然有个问题, 相信你也发现了, 就是会存在误判, 如果123会设置 Xi,Xj,Xk为 true, 456设置Xm,Xn 为 true, 那么可能某个数789是刚好哈希之后为 Xi,Xj,Xn, 这是就会把789这个不存在的数误判为存在.

只要设置足够多的哈希函数, 以及较大的位图大小可以降低误判的概率,而且很多场景对误判有一定的容忍度, 比如一个网址没有爬取但认为是被爬取之后也不会有很大的问题, 只是覆盖率不为100%了而已.

应用布隆过滤器来解决这个网页爬取的问题.

假设要爬取的网站有10亿, 可以用一个大小为10倍的位图存储, 也就是100亿个二进制位, 大约为1.2GB, 相比于散列表的100GB, 小了很多.
那么执行效率上呢? 需要进行多次的哈希运算, 这个是 CPU 密集型的操作, 散列表是需要赌气连接并进行字符串匹配, 操作设计很多的内存操作, 那肯定 CPU 操作比内存操作快得多. 理论上布隆过滤器判重更加快速.