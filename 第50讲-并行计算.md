**算法优化**不是没有尽头的, 比如普适的排序算法时间复杂度最好也就 O(n*logn), 还有一些在相同复杂度的情况下也能提升计算效率. 当然这跟算法的关系并不大, 但同样作为的优化手段是需要去注意的

## 如何借助并行手段提高计算效率.

有一个假设前提: 
物理支持最大16个线程

### 并行排序, 原数据大小8G

- 归并原理, 先将所有的数据任意分成16份, 每份500MB, 先对每一小份进行排序, 最后再将每个小份都合起来再排一次.
- 快排原理, 先遍历所有的数据, 找到区间范围, 从大到小的划分成16个区间, 将8GB 的数据分到这些区间里, 然后对每个区间进行排序, 最后把这16个区间连起来就自然有序了.

上述也充分体现了快排和归并排序的特点: 快排是分之前需要保证每一块之间的相对大小, 小块排完连接即可, 归并是任意分, 子问题排完还得再归并一次.

如果上述问题不是8G 的数据, 而是更为海量的比如1TB 的数据, 这个时候肯定数据是会储存到硬盘中, 如何对这1TB 的数据进行排序? 尽量需要减少 IO 操作, 比如按照系统分页的大小去取等优化手段.

### 并行查找

散列表是一个查询效率非常高的数据结构, 但是在往散列表中添加数据的时候装载因子会越来越大, 最终需要扩容, 比如一个散列表是2G, 如果此时已经到达2G 需要扩容,假设扩展到1.5倍也就是3GB, 那么此时是有1GB 是完全没用的, 这会导致空间占用的浪费, 只使用了60%左右.

但是如果划分成16份, 那么每一份大概是128MB, 某个散列表需要扩容时, 就会到128*1.5 = 192MB, 增加了64MB, 相比于原来的1GB 是要小很多的. 而且这样分成16份并行的查找, 效率理论上是比原来的快的.

### 并行进行字符串匹配

在字符串匹配算法的时候说了 **BF, BM,RK, KMP**算法, 这些算法在不是很长的字符串中查找关键词是很快的, 但是如果文本很大, 处理时间就会变得很长.

可以把整个文本分成16份, 启动16个线程进行处理, 并行的在16份中查找是否含有关键词, 注意一个问题, 有可能关键词刚好被分了, 假设关键词的长度为 m, 所以还需要额外的查找每一份末尾的m 个字符, 以及相邻下一份的起始 m 个字符相连的长度为2m的字符串, 判断是否含有关键词就不会遗漏了.

### 并行搜索

搜索已经讲了很多种, 比如广度优先搜索(BFS),深度优先搜索(DFS), Dijkstra 最短路径算法, A*启发式搜搜算法. 对于广度优先搜索也可以改造成并行搜索.

广度优先是一种逐层搜索的过程, 所以可以用两个队列来委会, 比如 A,B, 先将 A 中放入该层需要遍历的节点, 然后并行的获取 A 中的节点, 并把计算的结果推进 B 中, 然后对 B 做循环的操作.

### 总结

对并行的很重要的一点就是并行的任务之间是没有依赖关系的, 并行是一个工程上的实现, 当数据规模达到一定大时, 无法通过继续优化算法或者优化算法的成本很高时可以采用并行这种性价比较高的方式.(但是 JavaScript 的环境本身就是单线程的硬伤).

如果有 n 个任务, 相互之间有一定的依赖关系, 应该怎么去做呢? 构建一个拓扑图, 查找所有入度为0的点(也就是没有依赖的点), 可以先将其并行执行,然后再执行包含依赖的部分.